{
    "collab_server" : "",
    "contents" : "rm(list=ls(all.names = TRUE))\n\n# 1.install packages\nlibrary(tm)\nlibrary(tmcn)\nlibrary(jiebaR)\n\n# 2.set wd, set corpora\ngetwd()\nsetwd(\"C:/Users/user/Dropbox/R/R/data mining\")\nHK_NPC_jb <-  Corpus( DirSource() ,list(language = NA))\n\n\n# 3.remove...\nHK_NPC_jb <- tm_map( HK_NPC_jb, stripWhitespace ) # white space??\nHK_NPC_jb <- tm_map( HK_NPC_jb, removePunctuation ) # punctuation\nHK_NPC_jb <- tm_map( HK_NPC_jb, removeNumbers ) # numbers\nHK_NPC_jb <- tm_map( HK_NPC_jb,function( word ){ gsub( \"[A-Za-z0-9]\", \"\", word)}) # English & numbers\n\n\n\n\n# 4. change...\nHK_NPC_jb <- tm_map( HK_NPC_jb, PlainTextDocument ) # to plain text doc\nlength(HK_NPC_jb)\nHK_NPC_jb <- paste0(HK_NPC_jb[[1]]$content,collapse = \"\") # to string\nlength(HK_NPC_jb)\n\n# 5.Chinese text segmentation\ncut <- worker() # set segmentation worker\ncut_HK_NPC_jb <- cut[HK_NPC_jb] # segmentation\n\ndata_stw=read.table(file=\"stop.txt\")\n\nstopwords_CN=c(NULL)\nfor(i in 1:dim(data_stw)[1]){\n  stopwords_CN=c(stopwords_CN,data_stw[i,1])\n}\nstopwords[i]=paste(unlist(stopwords[i]),collapse =\", \")\n\nHK_NPC_jb=tm_map(HK_NPC_jb,removeWords,stopwords_CN) # 删除停用词\n\ncut_HK_NPC_jb_tab = table( cut_HK_NPC_jb )\n\n\nwrite.table(cut_HK_NPC_jb_tab, file=\"C:/Users/user/Dropbox/R/R/data mining/data7\")\n\n\n\n# 6.keywords\ncut_keywords <- worker(\"keywords\",topn=30) # set keywords worker\ncut_keywords[HK_NPC_jb] ",
    "created" : 1502281991923.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2523953448",
    "id" : "EC3A77F2",
    "lastKnownWriteTime" : 1502216164,
    "last_content_update" : 1502216164,
    "path" : "C:/Users/user/Dropbox/R/R/data mining/TM_preprocessing.R",
    "project_path" : "TM_preprocessing.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}